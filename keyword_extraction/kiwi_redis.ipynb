{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552a1aa4-c347-4c40-8c61-afa0ed787d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import redis\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# Redis 연결 정보 읽기\n",
    "REDIS_HOST = os.getenv('REDIS_HOST')\n",
    "REDIS_PORT = int(os.getenv('REDIS_PORT'))\n",
    "REDIS_USERNAME = os.getenv('REDIS_USERNAME')\n",
    "REDIS_PASSWORD = os.getenv('REDIS_PASSWORD')\n",
    "\n",
    "# Redis 클라이언트 설정\n",
    "r = redis.Redis(\n",
    "    host=REDIS_HOST,\n",
    "    port=REDIS_PORT,\n",
    "    username=REDIS_USERNAME,\n",
    "    password=REDIS_PASSWORD,\n",
    "    decode_responses=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef97dd2a-0b9d-4b45-959a-a532c50d61f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Redis database...\n",
      "Redis database cleared.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Completed_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 167\u001b[0m\n\u001b[1;32m    164\u001b[0m reset_redis()\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# 데이터 로드 및 텍스트 결합\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m combined_texts, df \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_combine_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# 상위 50개 키워드 추출\u001b[39;00m\n\u001b[1;32m    170\u001b[0m top_keywords \u001b[38;5;241m=\u001b[39m extract_top_keywords(combined_texts, top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 75\u001b[0m, in \u001b[0;36mload_and_combine_text\u001b[0;34m(data_folder)\u001b[0m\n\u001b[1;32m     72\u001b[0m combined_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     73\u001b[0m all_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     77\u001b[0m         filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_folder, filename)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Completed_csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from kiwipiepy import Kiwi\n",
    "import json\n",
    "\n",
    "# 데이터셋 경로 설정\n",
    "data_folder = \"../Completed_csv\"\n",
    "\n",
    "# 형태소 분석기 초기화\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# 불용어 리스트\n",
    "custom_stopwords = [\n",
    "    # 시간 관련\n",
    "    \"지난해\", \"이날\", \"오늘\", \"내일\", \"올해\", \"시간\", \"지난\", \"이번\", \"다음\", \n",
    "    \"현재\", \"그동안\", \"동안\", \"오전\", \"오후\", \"정오\", \"새벽\", \"하루\", \"주말\", \n",
    "    \"평일\", \"최근\", \"과거\", \"앞으로\", \"올해\", \"작년\", \"내년\", \"매일\", \"매주\", \"매월\", \n",
    "    \"이후\", \"이전\", \"이때\", \"그때\", \"그전\", \"그후\", \"얼마나\", \"종종\", \"한때\", \"언젠가\",\n",
    "    \"점심\", \"저녁\", \"아침\", \"밤\", \"밤새\", \"낮\", \"낮시간\", \"저녁시간\", \"오후시간\",\n",
    "    \n",
    "    # 공간 관련\n",
    "    \"대한\", \"관련\", \"서울\", \"한국\", \"대한민국\", \"곳\", \"지역\", \"전국\", \"해외\", \n",
    "    \"수도권\", \"지방\", \"동네\", \"거리\", \"건물\", \"도시\", \"국가\", \"세계\", \"지구\", \"근처\",\n",
    "    \n",
    "    # 단위 및 숫자\n",
    "    \"수\", \"것\", \"명\", \"번\", \"일\", \"월\", \"년\", \"억\", \"조\", \"퍼센트\", \"위\", \"분기\",\n",
    "    \"만원\", \"달러\", \"킬로미터\", \"미터\", \"그램\", \"톤\", \"리터\", \"배\", \"차례\", \"시간대\",\n",
    "    \n",
    "    # 조사 및 연결어\n",
    "    \"그리고\", \"하지만\", \"그러나\", \"또는\", \"또한\", \"등\", \"등등\", \"때문에\", \"이어서\", \n",
    "    \"뿐만\", \"이외\", \"위해\", \"더욱\", \"혹은\", \"따라서\", \"같이\", \"그렇지만\", \"결국\", \"즉\",\n",
    "    \n",
    "    # 기타 불용어\n",
    "    \"있다\", \"없다\", \"이다\", \"된다\", \"한다\", \"됐다\", \"중\", \"대한\", \"관련\", \"하기\", \"하는\",\n",
    "    \"부터\", \"까지\", \"만큼\", \"정도\", \"약\", \"이상\", \"이하\", \"속\", \"안\", \"밖\", \"뿐\", \"조차\",\n",
    "    \"처럼\", \"과\", \"또\", \"더\", \"모두\", \"전체\", \"각\", \"각각\", \"모든\", \"여러\", \"대부분\",\n",
    "    \n",
    "    # 주요 불용어 추가\n",
    "    \"최대\", \"대비\", \"가능\", \"공개\", \"규모\", \"증가\", \"감소\", \"전망\", \"기준\", \"수사\", \n",
    "    \"발표\", \"결정\", \"확인\", \"의견\", \"해결\", \"논의\", \"진행\", \"개최\", \"지원\", \"참여\",\n",
    "    \"성과\", \"방안\", \"조치\", \"역할\", \"상황\", \"현황\", \"내용\", \"자료\", \"정보\", \"관련\", \n",
    "    \"기대\", \"효과\", \"결과\", \"시작\", \"종료\", \"목적\", \"요청\", \"확보\", \"활동\", \"점검\",\n",
    "    \"조사\", \"문제\", \"과제\", \"성과\", \"변화\", \"대응\", \"위기\", \"차이\", \"현상\",\n",
    "\n",
    "    # 언론사\n",
    "    \"파이낸셜뉴스\", \"중앙일보\", \"서울경제\", \"아시아경제\", \"아시아투데이\",\n",
    "    \"세계일보\", \"경향신문\", \"한국경제\", \"KBS\", \"YTN\", \"국민일보\", \"한겨레\", \"아주경제\",\n",
    "    \"SBS\", \"DongAh\", \"머니투데이\",\n",
    "]\n",
    "\n",
    "# 데이터베이스 초기화 함수\n",
    "def reset_redis():\n",
    "    try:\n",
    "        print(\"Initializing Redis database...\")\n",
    "        r.flushdb()  # 현재 Redis 데이터베이스를 비웁니다.\n",
    "        print(\"Redis database cleared.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing Redis database: {e}\")\n",
    "        \n",
    "# 명사 추출\n",
    "def extract_nouns(text):\n",
    "    results = []\n",
    "    analysis = kiwi.analyze(text)\n",
    "    for token, pos, _, _ in analysis[0][0]:\n",
    "        if len(token) > 1 and (pos.startswith('N') or pos.startswith('SL')) and token not in custom_stopwords:\n",
    "            results.append(token)\n",
    "    return results\n",
    "\n",
    "# CSV 파일 로드 및 텍스트 결합\n",
    "def load_and_combine_text(data_folder):\n",
    "    combined_texts = []\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    for filename in os.listdir(data_folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            filepath = os.path.join(data_folder, filename)\n",
    "            df = pd.read_csv(filepath, encoding=\"utf-8\")\n",
    "            if \"title\" in df.columns and \"short_content\" in df.columns:\n",
    "                df[\"combined\"] = df[\"title\"].fillna(\"\") + \" \" + df[\"short_content\"].fillna(\"\")\n",
    "                combined_texts.extend(df[\"combined\"].tolist())\n",
    "                all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "    return combined_texts, all_data\n",
    "\n",
    "# 키워드 추출\n",
    "def extract_top_keywords(texts, top_n=50):\n",
    "    all_nouns = []\n",
    "    for text in texts:\n",
    "        nouns = extract_nouns(text)\n",
    "        all_nouns.extend(nouns)\n",
    "    word_counts = Counter(all_nouns)\n",
    "    return word_counts.most_common(top_n)\n",
    "\n",
    "# JSON 파일로 데이터 저장\n",
    "def save_preview_to_json(df, keywords, output_file=\"preview.json\"):\n",
    "    preview_data = {\n",
    "        \"keywords\": [kw for kw, _ in keywords],\n",
    "        \"articles\": {\n",
    "            keyword: df[df[\"combined\"].str.contains(keyword)].to_dict(orient=\"records\")\n",
    "            for keyword, _ in keywords\n",
    "        },\n",
    "        \"company_stats\": dict(Counter(df[\"company\"])),\n",
    "        \"keyword_stats\": {\n",
    "            keyword: len(df[df[\"combined\"].str.contains(keyword)]) for keyword, _ in keywords\n",
    "        },\n",
    "    }\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(preview_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"\\nPreview data saved to {output_file}.\")\n",
    "\n",
    "# redis에 데이터 저장\n",
    "def save_to_redis(df, keywords):\n",
    "    print(\"Starting to save data to Redis...\")\n",
    "\n",
    "    # 1. 키워드 목록 저장\n",
    "    valid_keywords = [kw for kw, _ in keywords if isinstance(kw, str)]\n",
    "    if not valid_keywords:\n",
    "        print(\"No valid keywords to save.\")\n",
    "        return\n",
    "\n",
    "    r.delete(\"keywords\")  # 기존 데이터를 삭제\n",
    "    r.sadd(\"keywords\", *valid_keywords)  # 유효한 키워드만 저장\n",
    "    print(\"Keywords saved.\")\n",
    "\n",
    "    # 2. 키워드별 기사 저장\n",
    "    for keyword in valid_keywords:\n",
    "        print(f\"Saving articles for keyword: {keyword}\")\n",
    "        articles = df[df[\"combined\"].str.contains(keyword)].copy()\n",
    "        articles = articles.drop(columns=[\"combined\"])\n",
    "\n",
    "        r.delete(f\"keyword:{keyword}:articles\")  # 기존 데이터 삭제\n",
    "        for _, row in articles.iterrows():\n",
    "            row_data = json.dumps(row.to_dict())\n",
    "            r.rpush(f\"keyword:{keyword}:articles\", row_data)\n",
    "        print(f\"Saved {len(articles)} articles for keyword: {keyword}.\")\n",
    "\n",
    "    # 3. 언론사별 기사 개수 저장\n",
    "    print(\"Saving company stats...\")\n",
    "    r.delete(\"company:stats\")\n",
    "    company_counts = Counter(df[\"company\"])\n",
    "    for company, count in company_counts.items():\n",
    "        r.hset(\"company:stats\", company, count)\n",
    "    print(\"Company stats saved.\")\n",
    "\n",
    "    # 4. 키워드별 기사 개수 저장\n",
    "    print(\"Saving keyword stats...\")\n",
    "    r.delete(\"keyword:stats\")\n",
    "    for keyword in valid_keywords:\n",
    "        count = len(df[df[\"combined\"].str.contains(keyword)])\n",
    "        r.hset(\"keyword:stats\", keyword, count)\n",
    "        print(f\"Keyword '{keyword}' has {count} articles.\")\n",
    "    print(\"Keyword stats saved.\")\n",
    "\n",
    "    print(\"Data saved to Redis.\")\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "\n",
    "    # redis 초기화\n",
    "    reset_redis()\n",
    "\n",
    "    # 데이터 로드 및 텍스트 결합\n",
    "    combined_texts, df = load_and_combine_text(data_folder)\n",
    "\n",
    "    # 상위 50개 키워드 추출\n",
    "    top_keywords = extract_top_keywords(combined_texts, top_n=50)\n",
    "    \n",
    "    # 상위 키워드 출력\n",
    "    print(\"\\n상위 50개 키워드:\")\n",
    "    for rank, (word, count) in enumerate(top_keywords, start=1):\n",
    "        print(f\"{rank}. {word} - {count}회 등장\")\n",
    "\n",
    "    # Redis에 저장\n",
    "    save_to_redis(df, top_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c951089-20ec-4338-86a9-0eda8edf1f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
