{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "552a1aa4-c347-4c40-8c61-afa0ed787d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import redis\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# Redis 연결 정보 읽기\n",
    "REDIS_HOST = os.getenv('REDIS_HOST')\n",
    "REDIS_PORT = int(os.getenv('REDIS_PORT'))\n",
    "REDIS_USERNAME = os.getenv('REDIS_USERNAME')\n",
    "REDIS_PASSWORD = os.getenv('REDIS_PASSWORD')\n",
    "\n",
    "# Redis 클라이언트 설정\n",
    "r = redis.Redis(\n",
    "    host=REDIS_HOST,\n",
    "    port=REDIS_PORT,\n",
    "    username=REDIS_USERNAME,\n",
    "    password=REDIS_PASSWORD,\n",
    "    decode_responses=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2292a66-37b7-4673-b1cf-d763a8ad4373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from kiwipiepy import Kiwi\n",
    "import json\n",
    "\n",
    "# 데이터셋 경로 설정\n",
    "data_folder = \"../Completed_csv\"\n",
    "\n",
    "# 형태소 분석기 초기화\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# 불용어 리스트\n",
    "custom_stopwords = [\n",
    "    # 시간 관련\n",
    "    \"지난해\", \"이날\", \"오늘\", \"내일\", \"올해\", \"시간\", \"지난\", \"이번\", \"다음\", \n",
    "    \"현재\", \"그동안\", \"동안\", \"오전\", \"오후\", \"정오\", \"새벽\", \"하루\", \"주말\", \n",
    "    \"평일\", \"최근\", \"과거\", \"앞으로\", \"올해\", \"작년\", \"내년\", \"매일\", \"매주\", \"매월\", \n",
    "    \"이후\", \"이전\", \"이때\", \"그때\", \"그전\", \"그후\", \"얼마나\", \"종종\", \"한때\", \"언젠가\",\n",
    "    \"점심\", \"저녁\", \"아침\", \"밤\", \"밤새\", \"낮\", \"낮시간\", \"저녁시간\", \"오후시간\",\n",
    "    \n",
    "    # 공간 관련\n",
    "    \"대한\", \"관련\", \"서울\", \"한국\", \"대한민국\", \"곳\", \"지역\", \"전국\", \"해외\", \n",
    "    \"수도권\", \"지방\", \"동네\", \"거리\", \"건물\", \"도시\", \"국가\", \"세계\", \"지구\", \"근처\",\n",
    "    \n",
    "    # 단위 및 숫자\n",
    "    \"수\", \"것\", \"명\", \"번\", \"일\", \"월\", \"년\", \"억\", \"조\", \"퍼센트\", \"위\", \"분기\",\n",
    "    \"만원\", \"달러\", \"킬로미터\", \"미터\", \"그램\", \"톤\", \"리터\", \"배\", \"차례\", \"시간대\",\n",
    "    \n",
    "    # 조사 및 연결어\n",
    "    \"그리고\", \"하지만\", \"그러나\", \"또는\", \"또한\", \"등\", \"등등\", \"때문에\", \"이어서\", \n",
    "    \"뿐만\", \"이외\", \"위해\", \"더욱\", \"혹은\", \"따라서\", \"같이\", \"그렇지만\", \"결국\", \"즉\",\n",
    "    \n",
    "    # 기타 불용어\n",
    "    \"있다\", \"없다\", \"이다\", \"된다\", \"한다\", \"됐다\", \"중\", \"대한\", \"관련\", \"하기\", \"하는\",\n",
    "    \"부터\", \"까지\", \"만큼\", \"정도\", \"약\", \"이상\", \"이하\", \"속\", \"안\", \"밖\", \"뿐\", \"조차\",\n",
    "    \"처럼\", \"과\", \"또\", \"더\", \"모두\", \"전체\", \"각\", \"각각\", \"모든\", \"여러\", \"대부분\",\n",
    "    \n",
    "    # 주요 불용어 추가\n",
    "    \"최대\", \"대비\", \"가능\", \"공개\", \"규모\", \"증가\", \"감소\", \"전망\", \"기준\", \"수사\", \n",
    "    \"발표\", \"결정\", \"확인\", \"의견\", \"해결\", \"논의\", \"진행\", \"개최\", \"지원\", \"참여\",\n",
    "    \"성과\", \"방안\", \"조치\", \"역할\", \"상황\", \"현황\", \"내용\", \"자료\", \"정보\", \"관련\", \n",
    "    \"기대\", \"효과\", \"결과\", \"시작\", \"종료\", \"목적\", \"요청\", \"확보\", \"활동\", \"점검\",\n",
    "    \"조사\", \"문제\", \"과제\", \"성과\", \"변화\", \"대응\", \"위기\", \"차이\", \"현상\",\n",
    "\n",
    "    # 언론사\n",
    "    \"파이낸셜뉴스\", \"중앙일보\", \"서울경제\", \"아시아경제\", \"아시아투데이\",\n",
    "    \"세계일보\", \"경향신문\", \"한국경제\", \"KBS\", \"YTN\", \"국민일보\", \"한겨레\", \"아주경제\",\n",
    "    \"SBS\", \"DongAh\", \"머니투데이\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c2639-df37-4ca9-b3df-5bf2a27ef465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터베이스 초기화 함수\n",
    "def reset_redis():\n",
    "    try:\n",
    "        print(\"Initializing Redis database...\")\n",
    "        r.flushdb()  # 현재 Redis 데이터베이스를 비웁니다.\n",
    "        print(\"Redis database cleared.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing Redis database: {e}\")\n",
    "        \n",
    "# 명사 추출\n",
    "def extract_nouns(text):\n",
    "    results = []\n",
    "    analysis = kiwi.analyze(text)\n",
    "    for token, pos, _, _ in analysis[0][0]:\n",
    "        if len(token) > 1 and (pos.startswith('N') or pos.startswith('SL')) and token not in custom_stopwords:\n",
    "            results.append(token)\n",
    "    return results\n",
    "\n",
    "# CSV 파일 로드 및 텍스트 결합\n",
    "def load_and_combine_text(data_folder):\n",
    "    combined_texts = []\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    for filename in os.listdir(data_folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            filepath = os.path.join(data_folder, filename)\n",
    "            df = pd.read_csv(filepath, encoding=\"utf-8\")\n",
    "            if \"title\" in df.columns and \"short_content\" in df.columns:\n",
    "                df[\"combined\"] = df[\"title\"].fillna(\"\") + \" \" + df[\"short_content\"].fillna(\"\")\n",
    "                combined_texts.extend(df[\"combined\"].tolist())\n",
    "                all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "    return combined_texts, all_data\n",
    "\n",
    "# 키워드 추출\n",
    "def extract_top_keywords(texts, top_n=50):\n",
    "    all_nouns = []\n",
    "    for text in texts:\n",
    "        nouns = extract_nouns(text)\n",
    "        all_nouns.extend(nouns)\n",
    "    word_counts = Counter(all_nouns)\n",
    "    return word_counts.most_common(top_n)\n",
    "\n",
    "# JSON 파일로 데이터 저장\n",
    "def save_preview_to_json(df, keywords, output_file=\"preview.json\"):\n",
    "    preview_data = {\n",
    "        \"keywords\": [kw for kw, _ in keywords],\n",
    "        \"articles\": {\n",
    "            keyword: df[df[\"combined\"].str.contains(keyword)].to_dict(orient=\"records\")\n",
    "            for keyword, _ in keywords\n",
    "        },\n",
    "        \"company_stats\": dict(Counter(df[\"company\"])),\n",
    "        \"keyword_stats\": {\n",
    "            keyword: len(df[df[\"combined\"].str.contains(keyword)]) for keyword, _ in keywords\n",
    "        },\n",
    "    }\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(preview_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"\\nPreview data saved to {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e953c293-5064-4826-85ee-7d54004c9b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redis에 데이터 저장\n",
    "def save_to_redis(df, keywords):\n",
    "    print(\"Starting to save data to Redis...\")\n",
    "\n",
    "    # 1. 키워드 목록 저장\n",
    "    valid_keywords = [kw for kw, _ in keywords if isinstance(kw, str)]\n",
    "    if not valid_keywords:\n",
    "        print(\"No valid keywords to save.\")\n",
    "        return\n",
    "\n",
    "    r.delete(\"keywords\")\n",
    "    r.sadd(\"keywords\", *valid_keywords)\n",
    "    print(\"Keywords saved.\")\n",
    "\n",
    "    # 2. 키워드별 기사 저장 및 3. 특정 키워드 내 언론사별 기사 개수 저장\n",
    "    for keyword in valid_keywords:\n",
    "        print(f\"Processing keyword: {keyword}\")\n",
    "        keyword_articles = df[df[\"combined\"].str.contains(keyword, case=False, na=False, regex=True)].copy()\n",
    "\n",
    "        if keyword_articles.empty:\n",
    "            print(f\"No articles found for keyword: {keyword}\")\n",
    "            continue  # 기사 없으면 저장하지 않음\n",
    "\n",
    "        # 기존 데이터 삭제\n",
    "        r.delete(f\"keyword:{keyword}:articles\")\n",
    "        r.delete(f\"keyword:{keyword}:company_stats\")\n",
    "\n",
    "        # 기사 저장 (JSON 형태)\n",
    "        for _, row in keyword_articles.iterrows():\n",
    "            row_data = json.dumps(row.to_dict(), ensure_ascii=False)\n",
    "            r.rpush(f\"keyword:{keyword}:articles\", row_data)\n",
    "\n",
    "        # 언론사별 기사 개수 저장\n",
    "        company_counts = Counter(keyword_articles[\"company\"])\n",
    "        for company, count in company_counts.items():\n",
    "            r.hset(f\"keyword:{keyword}:company_stats\", company, count)\n",
    "\n",
    "        print(f\"Saved {len(keyword_articles)} articles and company stats for keyword: {keyword}.\")\n",
    "\n",
    "    # 4. 키워드별 기사 개수 저장\n",
    "    print(\"Saving keyword stats...\")\n",
    "    r.delete(\"keyword:stats\")\n",
    "    for keyword in valid_keywords:\n",
    "        count = len(df[df[\"combined\"].str.contains(keyword)])\n",
    "        r.hset(\"keyword:stats\", keyword, count)\n",
    "        print(f\"Keyword '{keyword}' has {count} articles.\")\n",
    "    print(\"Keyword stats saved.\")\n",
    "\n",
    "    print(\"Data saved to Redis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552fdf12-8416-4dbf-9ef0-1c5ac15c5c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "\n",
    "    # redis 초기화\n",
    "    reset_redis()\n",
    "\n",
    "    # 데이터 로드 및 텍스트 결합\n",
    "    combined_texts, df = load_and_combine_text(data_folder)\n",
    "\n",
    "    # 상위 50개 키워드 추출\n",
    "    top_keywords = extract_top_keywords(combined_texts, top_n=50)\n",
    "    \n",
    "    # 상위 키워드 출력\n",
    "    print(\"\\n상위 50개 키워드:\")\n",
    "    for rank, (word, count) in enumerate(top_keywords, start=1):\n",
    "        print(f\"{rank}. {word} - {count}회 등장\")\n",
    "\n",
    "    # Redis에 저장\n",
    "    save_to_redis(df, top_keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
